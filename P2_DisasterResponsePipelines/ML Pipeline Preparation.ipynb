{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from IPython import display\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, BaseEstimator, TfidfTransformer\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql(\"SELECT * FROM InsertTableName;\", engine)\n",
    "X = df.message.values\n",
    "Y = pd.get_dummies(df.genre).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct</th>\n",
       "      <th>news</th>\n",
       "      <th>social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direct  news  social\n",
       "0       1     0       0\n",
       "1       1     0       0\n",
       "2       1     0       0\n",
       "3       1     0       0\n",
       "4       1     0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df.genre).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['direct', 'temperature of the medium of Port-au-prince. '],\n",
       "       ['direct',\n",
       "        'this is not a plan to help the schools which are victims? '],\n",
       "       ['direct', 'I NEED SOME INFORMATION ABOUT TEMPARATURE. '],\n",
       "       ['direct', '10 1 liter bottles of water in the east village'],\n",
       "       ['direct',\n",
       "        'We are in the area of Petit Goave, we would like .. we need tents and medication for flu/colds.. '],\n",
       "       ['direct',\n",
       "        'There are 5-7 people in the government that are taking portions of the aid coming to the people '],\n",
       "       ['direct',\n",
       "        'I miss school, I am away from my favorite friends, I am bored, I want to go to school, I do not want to ruin my future, I want to be someone respectable in '],\n",
       "       ['direct',\n",
       "        \"We are are in Gonaive. There are dead below and starving because all the students died in the earthquake. We are asking ( with/and? ) authorities ( about? ) our 'lean' situation here. \"],\n",
       "       ['direct',\n",
       "        'Are the earthquakes over? and if they happen again, what should we do?'],\n",
       "       ['direct',\n",
       "        'May i know if the schools will find help for the reopening class. '],\n",
       "       ['direct',\n",
       "        'where can I find public health in area kafou lamanten? thank you the answer already '],\n",
       "       ['direct',\n",
       "        'People who are wonded are dying of hunger. I am asking you to take a look at us because .. '],\n",
       "       ['direct',\n",
       "        \"Big up louco how you feel I'm healthy,it's just a divin grace \"],\n",
       "       ['direct', 'You guys forgot about people in Carrefour in Bertin.'],\n",
       "       ['direct',\n",
       "        'Good morning everybody, I see that you have me forgets because I have much hunger I was had gonaive. ']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.genre=='direct'].sample(15)[['genre', 'message']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # nromalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize and remove stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            result.append(lemmatizer.lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42, n_jobs=4)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"text_pipeline\", Pipeline([\n",
    "        (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "        (\"tfidf\", TfidfTransformer())\n",
    "    ])),\n",
    "    (\"clf\", MultiOutputClassifier(forest, n_jobs=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "* Split data into train and test sets\n",
    "* Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('text_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1...,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "           n_jobs=2))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "pipeline.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic model\n",
    "pred_y = pipeline.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     direct       0.91      0.93      0.92      3226\n",
      "       news       0.97      0.90      0.93      3912\n",
      "     social       0.97      0.82      0.89       727\n",
      "\n",
      "avg / total       0.95      0.90      0.92      7865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, target_names=[\"direct\", \"news\", \"social\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font: italic 25px Fira Sans, serif;'>         The naive model report:         <ol style='font: italic 25px Fira Sans, serif;'>             <li>Average F1 Score is 0.923</li>             <li>Average Precision Score is 0.944</li>             <li>Average Recall Score is 0.903</li>         </ol>     </p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display_html(\n",
    "    \"<p style='font: italic 25px Fira Sans, serif;'> \\\n",
    "        The naive model report: \\\n",
    "        <ol style='font: italic 25px Fira Sans, serif;'> \\\n",
    "            <li>Average F1 Score is {0:.3f}</li> \\\n",
    "            <li>Average Precision Score is {1:.3f}</li> \\\n",
    "            <li>Average Recall Score is {2:.3f}</li> \\\n",
    "        </ol> \\\n",
    "    </p>\".format( \n",
    "        f1_score(test_y, pred_y, average=\"micro\"),\n",
    "        precision_score(test_y, pred_y, average=\"micro\"),\n",
    "        recall_score(test_y, pred_y, average=\"micro\")\n",
    "    ), raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None, 'steps': [('text_pipeline', Pipeline(memory=None,\n",
       "        steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip...y=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))])),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
       "               oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "              n_jobs=2))], 'text_pipeline': Pipeline(memory=None,\n",
       "      steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...y=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))]), 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "            n_jobs=2), 'text_pipeline__memory': None, 'text_pipeline__steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x000001A52A508598>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))], 'text_pipeline__vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x000001A52A508598>,\n",
       "         vocabulary=None), 'text_pipeline__tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), 'text_pipeline__vect__analyzer': 'word', 'text_pipeline__vect__binary': False, 'text_pipeline__vect__decode_error': 'strict', 'text_pipeline__vect__dtype': numpy.int64, 'text_pipeline__vect__encoding': 'utf-8', 'text_pipeline__vect__input': 'content', 'text_pipeline__vect__lowercase': True, 'text_pipeline__vect__max_df': 1.0, 'text_pipeline__vect__max_features': None, 'text_pipeline__vect__min_df': 1, 'text_pipeline__vect__ngram_range': (1,\n",
       "  1), 'text_pipeline__vect__preprocessor': None, 'text_pipeline__vect__stop_words': None, 'text_pipeline__vect__strip_accents': None, 'text_pipeline__vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'text_pipeline__vect__tokenizer': <function __main__.tokenize(text)>, 'text_pipeline__vect__vocabulary': None, 'text_pipeline__tfidf__norm': 'l2', 'text_pipeline__tfidf__smooth_idf': True, 'text_pipeline__tfidf__sublinear_tf': False, 'text_pipeline__tfidf__use_idf': True, 'clf__estimator__bootstrap': True, 'clf__estimator__class_weight': None, 'clf__estimator__criterion': 'gini', 'clf__estimator__max_depth': None, 'clf__estimator__max_features': 'auto', 'clf__estimator__max_leaf_nodes': None, 'clf__estimator__min_impurity_decrease': 0.0, 'clf__estimator__min_impurity_split': None, 'clf__estimator__min_samples_leaf': 1, 'clf__estimator__min_samples_split': 2, 'clf__estimator__min_weight_fraction_leaf': 0.0, 'clf__estimator__n_estimators': 10, 'clf__estimator__n_jobs': 4, 'clf__estimator__oob_score': False, 'clf__estimator__random_state': 42, 'clf__estimator__verbose': 0, 'clf__estimator__warm_start': False, 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False), 'clf__n_jobs': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"text_pipeline\", Pipeline([\n",
    "        (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "        (\"tfidf\", TfidfTransformer())\n",
    "    ])),\n",
    "    (\"clf\", MultiOutputClassifier(forest))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "params = {\n",
    "#     'text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#     'text_pipeline__vect__max_df': (0.75, 1.0),\n",
    "    'text_pipeline__vect__max_features': (5000, 100000),\n",
    "#     'text_pipeline__tfidf__use_idf': (True, False),\n",
    "    'clf__estimator__n_estimators': [10, 20, 30],\n",
    "    'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "    'clf__estimator__max_depth': [4, 6, 10],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('text_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1...,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'text_pipeline__vect__max_features': (5000, 100000), 'clf__estimator__n_estimators': [10, 20, 30], 'clf__estimator__criterion': ['gini', 'entropy'], 'clf__estimator__max_depth': [4, 6, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict values\n",
    "pred_y = cv.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     direct       0.97      0.45      0.62      3226\n",
      "       news       0.83      0.96      0.89      3912\n",
      "     social       1.00      0.18      0.30       727\n",
      "\n",
      "avg / total       0.91      0.68      0.72      7865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, target_names=[\"direct\", \"news\", \"social\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font: italic 25px Fira Sans, serif;'>         The model report:         <ol style='font: italic 25px Fira Sans, serif;'>             <li>Average F1 Score is 0.763</li>             <li>Average Precision Score is 0.872</li>             <li>Average Recall Score is 0.678</li>         </ol>     </p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display_html(\n",
    "    \"<p style='font: italic 25px Fira Sans, serif;'> \\\n",
    "        The model report: \\\n",
    "        <ol style='font: italic 25px Fira Sans, serif;'> \\\n",
    "            <li>Average F1 Score is {0:.3f}</li> \\\n",
    "            <li>Average Precision Score is {1:.3f}</li> \\\n",
    "            <li>Average Recall Score is {2:.3f}</li> \\\n",
    "        </ol> \\\n",
    "    </p>\".format( \n",
    "        f1_score(test_y, pred_y, average=\"micro\"),\n",
    "        precision_score(test_y, pred_y, average=\"micro\"),\n",
    "        recall_score(test_y, pred_y, average=\"micro\")\n",
    "    ), raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__criterion': 'entropy',\n",
       " 'clf__estimator__max_depth': 10,\n",
       " 'clf__estimator__n_estimators': 20,\n",
       " 'text_pipeline__vect__max_features': 5000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunck_tokenize(text):\n",
    "    # nromalize text\n",
    "    text = re.sub(r\"#[a-zA-Z0-9]\", \"tagname\", text)\n",
    "    text = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"urlholder\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize and remove stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if token.lower() not in stop_words:\n",
    "            result.append(lemmatizer.lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    length = len(sent_tokenize(x))\n",
    "    chunck = False\n",
    "\n",
    "    for sentence in sent_tokenize(x):\n",
    "        pos_tags = nltk.pos_tag(chunck_tokenize(sentence))\n",
    "\n",
    "        try:\n",
    "            word, tag = pos_tags[0]\n",
    "\n",
    "            if \"VB\" in tag:\n",
    "                chunck = True\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            for word, tag in nltk.pos_tag(chunck_tokenize(sentence))[:3]:\n",
    "                if tag == \"NNP\":\n",
    "                    chunck = True\n",
    "                    break\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        if chunck:\n",
    "            break\n",
    "\n",
    "    return (length, chunck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordChunckExtract(BaseEstimator, TransformerMixin):\n",
    "    def starting_verb(self, text): \n",
    "        length = len(sent_tokenize(text))\n",
    "        chunck = False\n",
    "\n",
    "        for sentence in sent_tokenize(text):\n",
    "            pos_tags = nltk.pos_tag(chunck_tokenize(sentence))\n",
    "\n",
    "            try:\n",
    "                word, tag = pos_tags[0]\n",
    "\n",
    "                if \"VB\" in tag:\n",
    "                    chunck = True\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                for word, tag in nltk.pos_tag(chunck_tokenize(sentence))[:3]:\n",
    "                    if tag == \"NNP\":\n",
    "                        chunck = True\n",
    "                        break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if chunck:\n",
    "                break\n",
    "\n",
    "        return (length, chunck)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        result = pd.DataFrame()\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        result[\"length\"] = X_tagged.apply(lambda x: x[0] > 1)\n",
    "        result[\"chucnk\"] = X_tagged.apply(lambda x: x[1])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=42, n_jobs=4)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"features\", FeatureUnion([\n",
    "        (\"text_pipeline\", Pipeline([\n",
    "            (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "            (\"tfidf\", TfidfTransformer())\n",
    "        ])), \n",
    "        (\"exact_chunck\", WordChunckExtract())\n",
    "    ])),\n",
    "    (\"clf\", MultiOutputClassifier(forest, n_jobs=4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_d...,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "           n_jobs=4))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'features__text_pipeline__vect__max_features': (None, 5000, 10000), 'clf__estimator__n_estimators': [100, 150], 'clf__estimator__criterion': ['gini', 'entropy'], 'clf__estimator__max_depth': [12, 18, 25], 'features__transformer_weights': ({'text_pipeline': 1, 'starting_verb': 0.5},)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params\n",
    "params = {\n",
    "#     'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#     'features__text_pipeline__vect__max_df': (0.75, 1.0),\n",
    "    'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "#     'features__text_pipeline__tfidf__use_idf': (True, False),\n",
    "    'clf__estimator__n_estimators': [100, 150],\n",
    "    'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "    'clf__estimator__max_depth': [12, 18, 25],\n",
    "    'features__transformer_weights': (\n",
    "    {'text_pipeline': 1, 'starting_verb': 0.5},\n",
    "#     {'text_pipeline': 0.5, 'starting_verb': 1},\n",
    "#     {'text_pipeline': 0.8, 'starting_verb': 1},\n",
    ")\n",
    "\n",
    "}\n",
    "\n",
    "# train model\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict values\n",
    "pred_y = cv.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     direct       0.97      0.75      0.85      3226\n",
      "       news       0.89      0.97      0.93      3912\n",
      "     social       0.99      0.56      0.72       727\n",
      "\n",
      "avg / total       0.93      0.84      0.88      7865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, target_names=[\"direct\", \"news\", \"social\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font: italic 25px Fira Sans, serif;'>         The improved model report:         <ol style='font: italic 25px Fira Sans, serif;'>             <li>Average F1 Score is 0.883</li>             <li>Average Precision Score is 0.926</li>             <li>Average Recall Score is 0.844</li>         </ol>     </p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display_html(\n",
    "    \"<p style='font: italic 25px Fira Sans, serif;'> \\\n",
    "        The improved model report: \\\n",
    "        <ol style='font: italic 25px Fira Sans, serif;'> \\\n",
    "            <li>Average F1 Score is {0:.3f}</li> \\\n",
    "            <li>Average Precision Score is {1:.3f}</li> \\\n",
    "            <li>Average Recall Score is {2:.3f}</li> \\\n",
    "        </ol> \\\n",
    "    </p>\".format( \n",
    "        f1_score(test_y, pred_y, average=\"micro\"),\n",
    "        precision_score(test_y, pred_y, average=\"micro\"),\n",
    "        recall_score(test_y, pred_y, average=\"micro\")\n",
    "    ), raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pickle\", \"wb\") as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
